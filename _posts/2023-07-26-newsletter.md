---
layout: post
title: ARCHER2 Weekly Newsletter
date: 2023-07-26 11:00:00
author: ARCHER2 Service
tags: [newsletters] 
categories: [news]
---


- [Slurm: Scheduling jobs on ARCHER2]({{ page.url }}#slurm-scheduling-jobs-on-archer2), Online webinar, Today Wednesday 26th July 2023 15:00 - 16:00 BST
- [Parallel Performance Analysis using Scalasca]({{ page.url }}#parallel-performance-analysis-using-scalasca)
- [ARCHER2 Image and Video Competition 2023]({{ page.url }}#archer2-image-and-video-competition-2023)
- [Recently added known issues]({{ page.url }}#recently-added-known-issues)
- [Upcoming ARCHER2 training]({{ page.url }}#upcoming-archer2-training)

<!--more-->


## Slurm: Scheduling jobs on ARCHER2

Online, Wednesday 26th July 2023 15:00 - 16:00 BST

All access to the ARCHER2 compute nodes is via the Slurm workload manager, and writing batch submission scripts for standard MPI programs is relatively straightforward. However, it is useful to understand what actual happens under the hood which is sometimes not as simple as it may first appear.

There will be a 45-minute presentation at the start of this online tutorial, given by David Henty from ARCHER2 CSE support, which will address the following:

- how do batch scripts work?
- what happens to my Slurm job after I type sbatch?
- how do time limits and charging work?
- how do I access special queues?
- where does my job script actually run?
- how are processes and threads distributed across nodes or between the CPU-cores within a node?
- can I issue multiple srun commands in a single Slurm job?
- how do “interactive” batch jobs work?
- common issues; tips and tricks

[Full details, and join link](https://www.archer2.ac.uk/training/courses/230726-slurm-vt/


## Parallel Performance Analysis using Scalasca

22 - 23 August 2023 09:30 - 16:30 BST in [Oxford](https://www.archer2.ac.uk/training/locations/oxford-dtc)

[Scalasca](https://www.scalasca.org/) is a portable, free and open-source software tool that supports the performance optimisation of parallel programs by measuring and analysing their runtime behaviour. The analysis identifies potential performance bottlenecks – in particular those concerning communication and synchronisation – and offers guidance in exploring their causes. It uses execution profiles and traces generated by the community-developed Score-P instrumentation and measurement infrastructure.

[Scalasca](https://www.scalasca.org/) targets scientific and engineering applications based on the programming interfaces MPI and OpenMP, including hybrid applications using a combination of the two. The tool has been specifically designed for use on large-scale systems, but is also well suited for small and medium-scale HPC platforms. The software is available for free download under the New BSD open-source license.

This online course will cover how to use the tools in practice, delivered by members of the development team. Scalasca is portable across HPC systems, but for this course practical exercises will be conducted on the UK National HPC Service ARCHER2 (an HPC Cray EX system); all attendees will be given accounts on ARCHER2 for the duration of the course. Although example parallel programs will be provided, attendees are encouraged to analyse the performance of their own applications.

[Full details and registration]( https://www.archer2.ac.uk/training/courses/230822-scalasca/)




## ARCHER2 Image and Video Competition 2023

Your chance to win prizes, support excellence and promote the contribution of ARCHER2 to outstanding research.

The winning image or video, along with a selection of other entries, will also be featured on the ARCHER2 website and in EPCC and ARCHER2 publications.

### Key Details
- Competition Opens: 24 July 2023
- Submission Deadline: 1 September 2023
- Judging: September/October 2023
- Prizes:
   + Best image : £150
   + Best video : £150
   + Best early career researcher submission : £150
   + Overall winner, selected from the above three winners : additional £100

### What are we looking for?

The ARCHER2 Image Competition is an event for all users of ARCHER2 to share their images or videos of “ARCHER2 Enabling Research”

[Full details and entry form](https://www.archer2.ac.uk/community/image-comp/)
   

## Recently added known issues
 
The "[Known Issues](https://docs.archer2.ac.uk/known-issues/)" page of the ARCHER2 Documentation
<https://docs.archer2.ac.uk/known-issues/>
lists all current open known issues including a description of the issue, its symptoms and any work-arounds.

- No recent issues


## Upcoming ARCHER2 Training

- [Message-passing Programming with MPI](https://www.archer2.ac.uk/training/courses/210000-mpi-self-service/), Online, always-open self-service course
- [Shared Memory Programming with OpenMP](https://www.archer2.ac.uk/training/courses/210000-openmp-self-service/), Online, always-open self-service course
- [QM/MM with GROMACS + CP2K](https://www.archer2.ac.uk/training/courses/220000-gromacs-self-service/), Online, Always open - self-service course <br><br>
- [Slurm: Scheduling jobs on ARCHER2](https://www.archer2.ac.uk/training/courses/230726-slurm-vt), Online, Wednesday 26th July 2023 15:00 - 16:00 BST
- [Parallel Performance Analysis using Scalasca](https://www.archer2.ac.uk/training/courses/230822-scalasca/) , Oxford, 22 - 23 August 2023 09:30 - 16:30 BST 
- [Shared memory programming with OpenMP](https://www.archer2.ac.uk/training/courses/230928-openmp/), Imperial College London, 28 - 29 September 2023 10:00 - 17:00 BST

[Further details of upcoming training](https://www.archer2.ac.uk/training/#upcoming-training)

We always welcome researchers wishing to present their work in a webinar - please contact the [Service Desk](https://www.archer2.ac.uk/support-access/servicedesk.html) if you would be interested in presenting your work.

[Twitter](https://twitter.com/ARCHER2_HPC)

[Recordings of past courses](https://www.archer2.ac.uk/training/materials/)

[Recordings of past virtual tutorials](https://www.archer2.ac.uk/training/materials/webinars)
